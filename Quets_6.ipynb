{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpLVaxU_JG3a",
        "outputId": "e700e639-dcd6-49f6-dafe-6475580d4ca3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up5HLoSlI7Wg",
        "outputId": "e2afec15-9249-4b87-e26c-4d63c76d4f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 active IP addresses:\n",
            "+---------------+-------------+\n",
            "|             ip|request_count|\n",
            "+---------------+-------------+\n",
            "|  60.180.88.243|            1|\n",
            "|  220.65.162.38|            1|\n",
            "| 117.168.154.22|            1|\n",
            "|115.174.214.201|            1|\n",
            "| 170.27.105.112|            1|\n",
            "|   74.48.55.237|            1|\n",
            "| 101.181.92.218|            1|\n",
            "|   133.124.72.5|            1|\n",
            "| 121.62.201.221|            1|\n",
            "|138.241.209.141|            1|\n",
            "+---------------+-------------+\n",
            "\n",
            "Request count by HTTP method:\n",
            "+------+-------------------+\n",
            "|method|total_response_size|\n",
            "+------+-------------------+\n",
            "|  POST|              24847|\n",
            "|DELETE|              24999|\n",
            "|   PUT|              24896|\n",
            "|   GET|              25258|\n",
            "+------+-------------------+\n",
            "\n",
            "Number of 404 response codes: 24805\n",
            "Total response size by day:\n",
            "+----------+-------------------+\n",
            "| timestamp|total_response_size|\n",
            "+----------+-------------------+\n",
            "|2025-02-16|               1217|\n",
            "|2025-02-01|               1191|\n",
            "|2025-02-15|               1244|\n",
            "|2025-03-23|               1173|\n",
            "|2025-02-05|               1245|\n",
            "|2025-02-13|               1215|\n",
            "|2025-03-16|               1218|\n",
            "|2025-02-06|               1184|\n",
            "|2025-01-09|               1157|\n",
            "|2025-02-12|               1218|\n",
            "|2025-03-03|               1221|\n",
            "|2025-02-22|               1203|\n",
            "|2025-01-14|               1224|\n",
            "|2025-02-10|               1249|\n",
            "|2025-03-08|               1234|\n",
            "|2025-02-23|               1268|\n",
            "|2025-02-28|               1200|\n",
            "|2025-01-18|               1195|\n",
            "|2025-02-03|               1217|\n",
            "|2025-01-28|               1224|\n",
            "+----------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import desc, to_date\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Quets 15.12\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"web_server_logs.csv\", header=True, inferSchema=True)\n",
        "\n",
        "top10 = df.groupBy(\"ip\").count().orderBy(desc(\"count\")).limit(10)\n",
        "top10 = top10.withColumnRenamed(\"count\", \"request_count\")\n",
        "\n",
        "mthd = df.groupBy(\"method\").count()\n",
        "mthd = mthd.withColumnRenamed(\"count\", \"total_response_size\")\n",
        "\n",
        "error_404 = df.where(\"response_code=404\").count()\n",
        "\n",
        "data_day = df.withColumn(\"timestamp\", to_date(df.timestamp, 'yyyy-MM-dd'))\n",
        "data_day = data_day.groupBy(\"timestamp\").count()\n",
        "data_day = data_day.withColumnRenamed(\"count\", \"total_response_size\")\n",
        "\n",
        "\n",
        "print(\"Top 10 active IP addresses:\")\n",
        "top10.show()\n",
        "\n",
        "print('Request count by HTTP method:')\n",
        "mthd.show()\n",
        "\n",
        "print(f\"Number of 404 response codes: {error_404}\")\n",
        "\n",
        "print(\"Total response size by day:\")\n",
        "data_day.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}